{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import textwrap\n",
    "from enum import Enum\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "if \"macOS\" in platform.platform():\n",
    "    # Revert mp's start method to fork on MacOS\n",
    "    import multiprocessing\n",
    "\n",
    "    multiprocessing.set_start_method(\"fork\", force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and Categorize Student Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17846cc799540b78f3e07f0494391cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Category(Enum):\n",
    "    GOVERNMENT = \"government\"\n",
    "    MARKET_ANALYSIS = \"market_analysis\"\n",
    "    PHILOSOPHY = \"philosophy\"\n",
    "    PUZZLE = \"puzzle\"\n",
    "    STRATEGY = \"strategy\"\n",
    "\n",
    "\n",
    "class QuestionSummary(BaseModel):\n",
    "    category: Category = Field(description=\"The high-level category of the question\")\n",
    "    name: str = Field(description=\"A descriptive name based on the provided question. Must be three or fewer words\")\n",
    "\n",
    "\n",
    "def work(inputs, client=client):\n",
    "    _, row = inputs\n",
    "    prompt = row[\"prompt\"].strip()\n",
    "    try:\n",
    "        cot, final_output = row[\"response\"].strip(\"<think>\").split(\"</think>\")\n",
    "    except ValueError:\n",
    "        # Some students didn't copy the entire output including the CoT\n",
    "        cot, final_output = None, row[\"response\"]\n",
    "    result = {\"prompt\": prompt, \"cot\": cot, \"final_output\": final_output}\n",
    "\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Extract a summary of the user's question.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            response_format=QuestionSummary,\n",
    "        )\n",
    "        result[\"parse_result\"] = completion.choices[0].message.parsed\n",
    "    except Exception as error:\n",
    "        result[\"error\"] = {\"type\": str(type(error)), \"msg\": str(error)}\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "r1_qas = pd.read_csv(\"r1_students_queries.csv\")\n",
    "with Pool() as p:\n",
    "    parsed_prompts = [r for r in tqdm(p.imap_unordered(work, r1_qas.iterrows()), total=len(r1_qas))]\n",
    "\n",
    "# Flatten into a table\n",
    "recs = []\n",
    "for r in parsed_prompts:\n",
    "    rec = r.copy()\n",
    "    parse = rec.pop(\"parse_result\")\n",
    "    rec.update({\"name\": parse.name, \"category\": parse.category.value})\n",
    "    recs.append(rec)\n",
    "df = pd.DataFrame(recs).fillna(\"<|MISSING_STUDENT_INPUT/OUTPUT|>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Out Q&As to Markdown Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_QA = \"\"\"\n",
    "# {name}\n",
    "## Prompt\n",
    "```\n",
    "{prompt}\n",
    "```\n",
    "\n",
    "## Response\n",
    "### Chain-of-Though/Reasoning Chain (<think>{{cot}}</think>)\n",
    "```\n",
    "{cot}\n",
    "```\n",
    "\n",
    "### Final Output\n",
    "```\n",
    "{final_output}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    name = row[\"name\"]\n",
    "    filename = os.path.join(\"..\", \"r1-responses\", f\"{name.replace(' ', '_').lower()}.md\")\n",
    "    for_md = {\"name\": name}\n",
    "    for_md.update(\n",
    "        {\n",
    "            k: \"\\n\".join(textwrap.wrap(row[k], 80, replace_whitespace=False)).strip()\n",
    "            for k in [\"prompt\", \"cot\", \"final_output\"]\n",
    "        }\n",
    "    )\n",
    "    md = TEMPLATE_QA.format(**for_md)\n",
    "\n",
    "    with open(filename, \"w\") as out_file:\n",
    "        out_file.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Main MD File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_md = [\n",
    "    \"\"\"\n",
    "# Musings from R1\n",
    "Students from BUSN30135 used R1 to answer a variety of questions ranging from valuing a rare violin to assessing the market for teleportation to logic puzzles. This repo contains a handful of these questions, R1's chain of thought when answering, and R1's final response.\n",
    "\n",
    "## Index of Q&As\n",
    "\"\"\".strip()\n",
    "]\n",
    "\n",
    "for category, df_cat in df.sort_values([\"category\", \"name\"]).groupby(\"category\"):\n",
    "    main_md.append(f\"### {category.replace('_', ' ').title()}\")\n",
    "    for _, row in df_cat.iterrows():\n",
    "        name = row[\"name\"]\n",
    "        fn = f\"{name.replace(' ', '_').lower()}.md\"\n",
    "        main_md.append(f\"- [{row['name']}]({os.path.join('r1-responses', fn)})\")\n",
    "    main_md.append(\"\")\n",
    "\n",
    "with open(\"../README.md\", \"w\") as out_file:\n",
    "    out_file.write(\"\\n\".join(main_md))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
